{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from evgena.dataset import Dataset\n",
    "from evgena.model import TrainableTfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to network as supportive routines\n",
    "def conv_bn(x, filters, kernel_size, stride, padding, is_training):\n",
    "    x = tf.layers.conv2d(\n",
    "        x, filters, (kernel_size, kernel_size),\n",
    "        strides=(stride, stride), padding=padding, use_bias=False\n",
    "    )\n",
    "    x = tf.layers.batch_normalization(x, training=is_training)\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def residual_conv_bn(x, filters, kernel_size, stride, padding, is_training):\n",
    "    shortcut = x\n",
    "    x = tf.layers.conv2d(\n",
    "        x, filters, (kernel_size, kernel_size),\n",
    "        strides=(stride, stride), padding=padding, use_bias=False\n",
    "    )\n",
    "    x = tf.add(x, shortcut)\n",
    "    x = tf.layers.batch_normalization(x, training=is_training)\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete surrogate ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dataset = Dataset.from_nprecord('datasets/split_fashion_mnist.npz')\n",
    "target_model_path = 'models/different_seeds/2018-05-29_190930.bs-0128.lr-0.0010.seed-42/30-best_loss'\n",
    "target_model = TfModel(target_model_path)\n",
    "target_dataset_path = 'datasets/2018-05-29_190930_fashion_mnist.npz'\n",
    "\n",
    "target_dataset = Dataset.from_splits(\n",
    "    source_dataset.train.X, target_model(source.dataset.train.X),\n",
    "    source_dataset.val.X, target_model(source.dataset.val.X),\n",
    "    source_dataset.test.X, target_model(source.dataset.test.X),\n",
    "    metadata=dict(target_model_path=target_model_path, **source_dataset.metadata)\n",
    ")\n",
    "target_dataset.to_nprecord(target_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targetted surrogate ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dataset = Dataset.from_nprecord('datasets/split_fashion_mnist.npz')\n",
    "target_model_path = 'models/different_seeds/2018-05-29_190930.bs-0128.lr-0.0010.seed-42/30-best_loss'\n",
    "target_model = TfModel(target_model_path)\n",
    "target_label = 0\n",
    "target_dataset_path = 'datasets/2018-05-29_190930.0_fashion_mnist.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = []\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    source_split = getattr(source_dataset, split_name)\n",
    "    target_predictions = target_model(source_split.X)[:, target_label]\n",
    "    target_labels.append(\n",
    "        np.stack((target_predictions, 1 - target_predictions), axis=-1)\n",
    "    )\n",
    "train_labels, val_labels, test_labels = target_labels\n",
    "\n",
    "metadata = source_dataset.metadata\n",
    "metadata.update(\n",
    "    target_model_path=np.asarray(target_model_path),\n",
    "    target_label=np.asarray(target_label),\n",
    "    synset=np.array([True, False])\n",
    ")\n",
    "target_dataset = Dataset.from_splits(\n",
    "    source_dataset.train.X, train_labels,\n",
    "    source_dataset.val.X, val_labels,\n",
    "    source_dataset.test.X, test_labels,\n",
    "    metadata=metadata\n",
    ")\n",
    "target_dataset.to_nprecord(target_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cnn(images, labels, is_training, global_step):\n",
    "    x = images\n",
    "    \n",
    "    x = conv_bn(x, 32, 3, 1, 'same', is_training)\n",
    "    x = tf.layers.max_pooling2d(x, (2, 2), (2, 2))\n",
    "    x = conv_bn(x, 64, 3, 1, 'same', is_training)\n",
    "    x = tf.layers.max_pooling2d(x, (2, 2), (2, 2))\n",
    "    x = conv_bn(x, 128, 3, 1, 'same', is_training)\n",
    "    x = tf.layers.flatten(x)\n",
    "    x = tf.layers.dropout(x, training=is_training)\n",
    "    x = tf.layers.dense(x, 128, activation=tf.nn.relu)\n",
    "    x = tf.layers.dropout(x, training=is_training)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrainableTfModel.construct(binary_cnn, 'datasets/2018-05-29_190930.0_fashion_mnist.npz', 128, 0.001, tag='test_sigmoid_surrogate', inference_batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
