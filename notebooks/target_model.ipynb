{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from evgena.model import TrainableTfModel\n",
    "from evgena.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST models ##\n",
    "- \"official\" [benchmark](https://github.com/zalandoresearch/fashion-mnist#benchmark)\n",
    "    - 3 Conv, pool, dense, BN (target 0.934)\n",
    "    - [DenseNet](https://arxiv.org/pdf/1608.06993.pdf) (target 0.954)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(x, filters, kernel_size, stride, padding, is_training):\n",
    "    x = tf.layers.conv2d(\n",
    "        x, filters, (kernel_size, kernel_size),\n",
    "        strides=(stride, stride), padding=padding, use_bias=False\n",
    "    )\n",
    "    x = tf.layers.batch_normalization(x, training=is_training)\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(images, labels, is_training, global_step):\n",
    "    x = images\n",
    "    x = conv_bn(x, 32, 3, 1, 'same', is_training)\n",
    "    x = tf.layers.max_pooling2d(x, (2, 2), (2, 2))\n",
    "    x = tf.layers.dropout(x, rate=0.3, training=is_training)\n",
    "    x = conv_bn(x, 64, 3, 1, 'same', is_training)\n",
    "    x = tf.layers.max_pooling2d(x, (2, 2), (2, 2))\n",
    "    x = tf.layers.dropout(x, rate=0.3, training=is_training)\n",
    "    x = conv_bn(x, 128, 3, 1, 'same', is_training)\n",
    "    x = tf.layers.flatten(x)\n",
    "    x = tf.layers.dropout(x, rate=0.3, training=is_training)\n",
    "    x = tf.layers.dense(x, 128, activation=tf.nn.relu)\n",
    "    x = tf.layers.dropout(x, rate=0.3, training=is_training)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seed in zip(range(10), np.random.randint(65536, size=10, dtype=np.int32)):\n",
    "    model = TrainableTfModel.construct(\n",
    "        cnn, 'datasets/stratified_fashion_mnist_{}_fold.npz'.format(i), 128, 0.001, seed=int(seed),\n",
    "        moment_axis=(0, 1, 2), weight_decay=0.0001, tag='simple_3cnn_10_fold_end_tuning', inference_batch_size=4096\n",
    "    )\n",
    "    \n",
    "    model.train(64)\n",
    "    model.train(32, from_checkpoint='last', learning_rate=0.0002)\n",
    "    model.train(32, from_checkpoint='last', learning_rate=0.00004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet:\n",
    "    def __init__(\n",
    "        self, growth_rate: int, depth: int, block_count: int,\n",
    "        use_bc: bool = False, compression: float = 1.0, dropout: float = None\n",
    "    ):\n",
    "        self.growth_rate = growth_rate\n",
    "        self.depth = depth\n",
    "        self.block_count = block_count\n",
    "        self.block_depth = (depth - (block_count + 1)) // (block_count * (2 if use_bc else 1))\n",
    "        self.use_bc = use_bc\n",
    "        self.compression = compression\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def _activation(self, x, is_training):\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x\n",
    "        \n",
    "    def _bottleneck(self, x, is_training):\n",
    "        x = self._activation(x, is_training)\n",
    "        x = tf.layers.conv2d(x, 4 * self.growth_rate, 1, use_bias=False)\n",
    "        return x\n",
    "        \n",
    "    def _composite_f(self, x, filters, kernel_size, is_training):\n",
    "        x = self._activation(x, is_training)\n",
    "        x = tf.layers.conv2d(x, filters, kernel_size, padding='same', use_bias=False)\n",
    "        if self.dropout is not None:\n",
    "            x = tf.layers.dropout(x, rate=self.dropout, training=is_training)\n",
    "        return x\n",
    "        \n",
    "    def _dense_block(self, x, is_training):\n",
    "        for layer in range(self.block_depth):\n",
    "            input_x = x\n",
    "            if self.use_bc:\n",
    "                x = self._bottleneck(x, is_training)\n",
    "            x = self._composite_f(x, self.growth_rate, 3, is_training)\n",
    "            x = tf.concat((input_x, x), axis=3)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def _transition_layer(self, x, is_training):\n",
    "        x = self._composite_f(x, int(self.compression * int(x.get_shape()[-1])), 1, is_training)\n",
    "        x = tf.layers.average_pooling2d(x, 2, 2)\n",
    "        return x\n",
    "        \n",
    "    def __call__(self, images, labels, is_training, global_step):\n",
    "        x = tf.layers.conv2d(images, max(16, int(self.growth_rate / self.compression)), 3, padding='same', use_bias=False)\n",
    "        \n",
    "        for b_i in range(self.block_count - 1):\n",
    "            x = self._dense_block(x, is_training)\n",
    "            x = self._transition_layer(x, is_training)\n",
    "            \n",
    "        x = self._dense_block(x, is_training)\n",
    "        \n",
    "        x = self._activation(x, is_training)\n",
    "        x = tf.reduce_mean(x, axis=(1, 2))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seed in zip(range(10), np.random.randint(65536, size=10, dtype=np.int32)):\n",
    "    model = TrainableTfModel.construct(\n",
    "        (lambda *args, **kwargs: DenseNet(8, 52, 3, use_bc=True, compression=0.5, dropout=0.2)(*args, **kwargs)),\n",
    "        'datasets/stratified_fashion_mnist_{}_fold.npz'.format(i), 128, 0.1, seed=int(seed), \n",
    "        optimizer=(lambda lr: tf.train.MomentumOptimizer(lr, 0.9, use_nesterov=True)),\n",
    "        moment_axis=(0, 1, 2), weight_decay=0.0001, tag='dense_net_BC_8_52_10_fold_nesterov', inference_batch_size=1024\n",
    "    )\n",
    "    \n",
    "    model.train(64)\n",
    "    model.train(32, from_checkpoint='last', learning_rate=0.01)\n",
    "    model.train(32, from_checkpoint='last', learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([np.product(var.shape.as_list()) for var in model._session.graph.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
