{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from itertools import chain\n",
    "from typing import Union, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from evgena.dataset import Dataset\n",
    "from evgena.model import TrainableTfModel, TfModel\n",
    "from evgena.data_transformations import images_to_BHWC, decode_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure gradient methods #\n",
    "- [FGSM](#fgsm)\n",
    "- [black-box methods](#black-box)\n",
    "\n",
    "```python\n",
    "def stub(\n",
    "    model: TfModel, images: np.ndarray, labels: Union[int, Sequence[int]],\n",
    "    *method_specific_arguments,\n",
    "    is_targeted: bool = True, common_pattern: bool = True\n",
    "):\n",
    "    NotImplemented\n",
    "```\n",
    "\n",
    "## FGSM ##\n",
    "- [paper](https://arxiv.org/pdf/1412.6572.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm(\n",
    "    model: TrainableTfModel, images: np.ndarray, labels: Union[int, Sequence[int]],\n",
    "    confidence_bound: float, step_size: float = (1/255), max_diff: float = 0.1,\n",
    "    max_steps: int = 2048, is_targeted: bool = True\n",
    ") -> np.ndarray:\n",
    "    images = images_to_BHWC(images)\n",
    "    step_count = np.zeros(shape=len(images), dtype=np.int32)\n",
    "    labels = labels if hasattr(labels, '__len__') else np.array([labels] * len(images))\n",
    "    \n",
    "    noise = np.zeros(images.shape, dtype=np.float32)\n",
    "    \n",
    "    if is_targeted:\n",
    "        grad_sign = -1\n",
    "        scores = np.zeros(shape=len(images), dtype=np.float32)\n",
    "    else:\n",
    "        grad_sign = 1\n",
    "        confidence_bound = 1 - confidence_bound\n",
    "        scores = np.ones(shape=len(images), dtype=np.float32)\n",
    "    \n",
    "    adv_ex = np.clip(images + noise, 0, 1)\n",
    "    \n",
    "    for s_i in chain.from_iterable([range(max_steps), [-1]]):\n",
    "        curr_mask = (scores < confidence_bound) if is_targeted else (scores >= confidence_bound)\n",
    "        \n",
    "        if not curr_mask.any():\n",
    "            break\n",
    "        \n",
    "        curr_noise = grad_sign * step_size * np.sign(\n",
    "            model.gradients(adv_ex[curr_mask], labels[curr_mask])\n",
    "        )\n",
    "        \n",
    "        noise[curr_mask] = np.clip(\n",
    "            noise[curr_mask] + curr_noise,\n",
    "            - max_diff, max_diff\n",
    "        )\n",
    "        \n",
    "        adv_ex[curr_mask] = np.clip((images + noise)[curr_mask], 0, 1)\n",
    "        scores[curr_mask] = model(adv_ex[curr_mask])[np.arange(curr_mask.sum()), labels[curr_mask]]\n",
    "        step_count[curr_mask] = s_i\n",
    "    \n",
    "    return adv_ex, noise, step_count, scores if is_targeted else 1 - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrogate_fgsm(\n",
    "    target_model: TfModel, surrogate_model: TrainableTfModel, images: np.ndarray, labels: Union[int, Sequence[int]],\n",
    "    confidence_bound: float, step_size: float = (1/255), max_diff: float = 0.1,\n",
    "    max_steps: int = 128, is_targeted: bool = True\n",
    ") -> np.ndarray:\n",
    "    images = images_to_BHWC(images)\n",
    "    step_count = np.zeros(shape=len(images), dtype=np.int32)\n",
    "    labels = labels if hasattr(labels, '__len__') else np.array([labels] * len(images))\n",
    "    \n",
    "    noise = np.zeros(images.shape, dtype=np.float32)\n",
    "    \n",
    "    if is_targeted:\n",
    "        grad_sign = -1\n",
    "        scores = np.zeros(shape=len(images), dtype=np.float32)\n",
    "    else:\n",
    "        grad_sign = 1\n",
    "        confidence_bound = 1 - confidence_bound\n",
    "        scores = np.ones(shape=len(images), dtype=np.float32)\n",
    "    \n",
    "    adv_ex = np.clip(images + noise, 0, 1)\n",
    "    \n",
    "    for s_i in chain.from_iterable([range(max_steps), [-1]]):\n",
    "        curr_mask = (scores < confidence_bound) if is_targeted else (scores >= confidence_bound)\n",
    "        \n",
    "        if not curr_mask.any():\n",
    "            break\n",
    "        \n",
    "        curr_noise = grad_sign * step_size * np.sign(\n",
    "            surrogate_model.gradients(adv_ex[curr_mask], labels[curr_mask])\n",
    "        )\n",
    "        \n",
    "        noise[curr_mask] = np.clip(\n",
    "            noise[curr_mask] + curr_noise,\n",
    "            - max_diff, max_diff\n",
    "        )\n",
    "        \n",
    "        adv_ex[curr_mask] = np.clip(images[curr_mask] + noise[curr_mask], 0, 1)\n",
    "        scores[curr_mask] = target_model(adv_ex[curr_mask])[np.arange(curr_mask.sum()), labels[curr_mask]]\n",
    "        step_count[curr_mask] = s_i\n",
    "    \n",
    "    return adv_ex, noise, step_count, scores if is_targeted else 1 - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_surrogate_fgsm(\n",
    "    target_model: TfModel, surrogate_model: TrainableTfModel, images: np.ndarray,\n",
    "    surrogate_class: int, confidence_bound: float, step_size: float = (1/255),\n",
    "    max_diff: float = 0.1, max_steps: int = 128, is_targeted: bool = True\n",
    ") -> np.ndarray:\n",
    "    images = images_to_BHWC(images)\n",
    "    step_count = np.zeros(shape=len(images), dtype=np.int32)\n",
    "    labels = np.array([0] * len(images))\n",
    "    noise = np.zeros(images.shape, dtype=np.float32)\n",
    "    \n",
    "    if is_targeted:\n",
    "        grad_sign = -1\n",
    "        scores = np.zeros(shape=len(images), dtype=np.float32)\n",
    "    else:\n",
    "        grad_sign = 1\n",
    "        confidence_bound = 1 - confidence_bound\n",
    "        scores = np.ones(shape=len(images), dtype=np.float32)\n",
    "    \n",
    "    adv_ex = np.clip(images + noise, 0, 1)\n",
    "    \n",
    "    for s_i in chain.from_iterable([range(max_steps), [-1]]):\n",
    "        curr_mask = (scores < confidence_bound) if is_targeted else (scores >= confidence_bound)\n",
    "        \n",
    "        if not curr_mask.any():\n",
    "            break\n",
    "        \n",
    "        curr_noise = grad_sign * step_size * np.sign(\n",
    "            surrogate_model.gradients(adv_ex[curr_mask], labels[curr_mask])\n",
    "        )\n",
    "        \n",
    "        noise[curr_mask] = np.clip(\n",
    "            noise[curr_mask] + curr_noise,\n",
    "            - max_diff, max_diff\n",
    "        )\n",
    "        \n",
    "        adv_ex[curr_mask] = np.clip(images[curr_mask] + noise[curr_mask], 0, 1)\n",
    "        scores[curr_mask] = target_model(adv_ex[curr_mask])[:, surrogate_class]\n",
    "        step_count[curr_mask] = s_i\n",
    "    \n",
    "    return adv_ex, noise, step_count, scores if is_targeted else 1 - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrogate_multi_fgsm(\n",
    "    target_models: Sequence[TfModel], surrogate_model: TrainableTfModel, images: np.ndarray, labels: Union[int, Sequence[int]],\n",
    "    confidence_bound: float, step_size: float = (1/255), max_diff: float = 0.1,\n",
    "    max_steps: int = 128, is_targeted: bool = True\n",
    ") -> np.ndarray:\n",
    "    images = images_to_BHWC(images)\n",
    "    labels = labels if hasattr(labels, '__len__') else np.array([labels] * len(images))\n",
    "    \n",
    "    step_counts = [np.zeros(shape=len(images), dtype=np.int32) for _ in target_models]\n",
    "    \n",
    "    noise = np.zeros(images.shape, dtype=np.float32)\n",
    "    adv_exs = [np.clip(images + noise, 0, 1) for _ in target_models]\n",
    "    scores = [target_model(images)[np.arange(len(images)), labels] for target_model in target_models]\n",
    "    \n",
    "    if is_targeted:\n",
    "        grad_sign = -1\n",
    "    else:\n",
    "        grad_sign = 1\n",
    "        confidence_bound = 1 - confidence_bound\n",
    "    \n",
    "    for s_i in chain.from_iterable([range(max_steps), [-1]]):\n",
    "        masks = [\n",
    "            (score < confidence_bound) if is_targeted else (score >= confidence_bound)\n",
    "            for score in scores\n",
    "        ]\n",
    "        joint_mask = np.any(curr_masks, axis=0)\n",
    "        \n",
    "        if not joint_mask.any():\n",
    "            break\n",
    "        \n",
    "        curr_noise = grad_sign * step_size * np.sign(\n",
    "            surrogate_model.gradients(\n",
    "                np.clip(images[joint_mask] + noise[joint_mask], 0, 1), labels[joint_mask]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        noise[joint_mask] = np.clip(\n",
    "            noise[joint_mask] + curr_noise,\n",
    "            - max_diff, max_diff\n",
    "        )\n",
    "        \n",
    "        joint_adv_ex = np.clip(images[joint_mask] + noise[joint_mask], 0, 1)\n",
    "        for target_model, adv_ex, score, step_count, mask in zip(\n",
    "            target_models, adv_exs, scores, step_counts, masks\n",
    "        ):\n",
    "            curr_adv_ex = joint_adv_ex[mask[joint_mask]]\n",
    "            adv_ex[mask] = curr_adv_ex\n",
    "            scores[mask] = target_model(curr_adv_ex)[np.arange(mask.sum()), labels[mask]]\n",
    "            step_count[mask] = s_i\n",
    "    \n",
    "    return [\n",
    "        (adv_ex, noise, step_count, score if is_targeted else 1 - score)\n",
    "        for adv_ex, step_count, score in zip(adv_exs, step_counts, scores)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White-box attack ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = 'simple_cnn'\n",
    "# model_type = 'densenet'\n",
    "\n",
    "for m_i in range(10):\n",
    "    target_model_dir = 'models/fashion_mnist_{t}/fold_{k}/'.format(t=model_type, k=m_i)\n",
    "    target_model = TrainableTfModel(target_model_dir)\n",
    "    \n",
    "    with open(target_model_dir + 'config.json', 'r') as config_f:\n",
    "        config = json.load(config_f)\n",
    "    dataset = Dataset.from_nprecord(config['dataset_path'])\n",
    "    \n",
    "    adv_ex, noise, step_count, scores = fgsm(target_model, dataset.test.X, dataset.test.y, 0.5, is_targeted=False)\n",
    "    np.savez_compressed(\n",
    "        'experiments/{}_{}_fgsm_white_single_non_targeted.npz'.format(model_type, m_i),\n",
    "        adv_ex=adv_ex, noise=noise, step_count=step_count, scores=scores\n",
    "    )\n",
    "    print(':', end='')\n",
    "    \n",
    "    for l_i in range(10):\n",
    "        adv_ex, noise, step_count, scores = fgsm(target_model, dataset.test.X[decode_labels(dataset.test.y) != l_i], l_i, 0.5, is_targeted=True)\n",
    "        np.savez_compressed(\n",
    "            'experiments/{}_{}_fgsm_white_single_targeted_{}.npz'.format(model_type, m_i, l_i),\n",
    "            adv_ex=adv_ex, noise=noise, step_count=step_count, scores=scores\n",
    "        )\n",
    "        print('.', end='')\n",
    "    print(':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain surrogate ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_type = 'densenet'\n",
    "surrogate_type = 'simplenet'\n",
    "\n",
    "if target_type == 'simplenet':\n",
    "    target_model = TrainableTfModel('models/fashion_mnist_simplenet/fold_7')\n",
    "    forbid_fold = 7\n",
    "else:\n",
    "    target_model = TrainableTfModel('models/fashion_mnist_densenet/fold_0')\n",
    "    forbid_fold = 0\n",
    "dataset = Dataset.from_nprecord(target_model._config.dataset_path)\n",
    "\n",
    "for m_i in range(10):\n",
    "    if m_i == forbid_fold:\n",
    "        continue\n",
    "    \n",
    "    surrogate_model = TrainableTfModel(\n",
    "        'models/fashion_mnist_{t}/fold_{k}/'.format(t=surrogate_type, k=m_i)\n",
    "    )\n",
    "    \n",
    "    adv_ex, noise, step_count, scores = surrogate_fgsm(\n",
    "        target_model, surrogate_model, dataset.test.X,\n",
    "        dataset.test.y, 0.5, is_targeted=False\n",
    "    )\n",
    "    np.savez_compressed(\n",
    "        'experiments/fgsm/plain_surrogate/{tt}/single/{st}/{st}_{tt}_{f}_fgsm_plain_surrogate_single_non_targeted.npz'.format(\n",
    "            tt=target_type, st=surrogate_type, f=m_i),\n",
    "        adv_ex=adv_ex, noise=noise, step_count=step_count, scores=scores\n",
    "    )\n",
    "    print(':', end='')\n",
    "    \n",
    "    for l_i in range(10):\n",
    "        adv_ex, noise, step_count, scores = surrogate_fgsm(\n",
    "            target_model, surrogate_model, dataset.test.X[decode_labels(dataset.test.y) != l_i],\n",
    "            l_i, 0.5, is_targeted=True\n",
    "        )\n",
    "        np.savez_compressed(\n",
    "            'experiments/fgsm/plain_surrogate/{tt}/single/{st}/{st}_{tt}_{f}_fgsm_plain_surrogate_single_targeted_{l}.npz'.format(\n",
    "                tt=target_type, st=surrogate_type, f=m_i, l=l_i),\n",
    "            adv_ex=adv_ex, noise=noise, step_count=step_count, scores=scores\n",
    "        )\n",
    "        print('.', end='')\n",
    "    print(':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full surrogate ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_type = 'densenet'\n",
    "surrogate_type = 'simplenet'\n",
    "\n",
    "if target_type == 'simplenet':\n",
    "    target_model = TrainableTfModel('models/fashion_mnist_simplenet/fold_7')\n",
    "else:\n",
    "    target_model = TrainableTfModel('models/fashion_mnist_densenet/fold_0')\n",
    "dataset = Dataset.from_nprecord(target_model._config.dataset_path)\n",
    "\n",
    "for m_i in range(10):\n",
    "    surrogate_model = TrainableTfModel(\n",
    "        'models/reduced_{tt}_fashion_mnist_{st}/fold_{k}'.format(\n",
    "            st=surrogate_type, tt=target_type, k=m_i\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    adv_ex, noise, step_count, scores = surrogate_fgsm(\n",
    "        target_model, surrogate_model, dataset.test.X,\n",
    "        dataset.test.y, 0.5, is_targeted=False\n",
    "    )\n",
    "    np.savez_compressed(\n",
    "        'experiments/{st}_{tt}_{k}_fgsm_reduced_surrogate_single_non_targeted.npz'.format(\n",
    "            st=surrogate_type, tt=target_type, k=m_i\n",
    "        ),\n",
    "        adv_ex=adv_ex, noise=noise, step_count=step_count, scores=scores\n",
    "    )\n",
    "    print(':', end='')\n",
    "    \n",
    "    for l_i in range(10):\n",
    "        adv_ex, noise, step_count, scores = surrogate_fgsm(\n",
    "            target_model, surrogate_model, dataset.test.X[decode_labels(dataset.test.y) != l_i],\n",
    "            l_i, 0.5, is_targeted=True\n",
    "        )\n",
    "        np.savez_compressed(\n",
    "            'experiments/{st}_{tt}_{k}_fgsm_reduced_surrogate_single_targeted_{l}.npz'.format(\n",
    "                st=surrogate_type, tt=target_type, k=m_i, l=l_i\n",
    "            ),\n",
    "            adv_ex=adv_ex, noise=noise, step_count=step_count, scores=scores\n",
    "        )\n",
    "        print('.', end='')\n",
    "    print(':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary surrogate ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_class = 3\n",
    "target_type = 'simplenet'\n",
    "surrogate_type = 'simplenet'\n",
    "\n",
    "if target_type == 'simplenet':\n",
    "    target_model = TrainableTfModel('models/fashion_mnist_simplenet/fold_7')\n",
    "else:\n",
    "    target_model = TrainableTfModel('models/fashion_mnist_densenet/fold_0')\n",
    "dataset = Dataset.from_nprecord(target_model._config.dataset_path)\n",
    "\n",
    "for m_i in range(10):\n",
    "    surrogate_model = TrainableTfModel(\n",
    "        'models/dress_{tt}_fashion_mnist_{st}/fold_{k}'.format(\n",
    "            st=surrogate_type, tt=target_type, k=m_i\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    adv_ex, noise, step_count, scores = binary_surrogate_fgsm(\n",
    "        target_model, surrogate_model, dataset.test.X[decode_labels(dataset.test.y) == median_class],\n",
    "        median_class, 0.5, is_targeted=False\n",
    "    )\n",
    "    np.savez_compressed(\n",
    "        'experiments/fgsm/binary_surrogate/{tt}/single/{st}/{st}_{tt}_{k}_fgsm_reduced_surrogate_single_non_targeted.npz'.format(\n",
    "            st=surrogate_type, tt=target_type, k=m_i\n",
    "        ),\n",
    "        adv_ex=adv_ex, noise=noise, step_count=step_count, scores=scores\n",
    "    )\n",
    "    print(':', end='')\n",
    "    \n",
    "    adv_ex, noise, step_count, scores = binary_surrogate_fgsm(\n",
    "        target_model, surrogate_model, dataset.test.X[decode_labels(dataset.test.y) != median_class],\n",
    "        median_class, 0.5, is_targeted=True\n",
    "    )\n",
    "    np.savez_compressed(\n",
    "        'experiments/fgsm/binary_surrogate/{tt}/single/{st}/{st}_{tt}_{k}_fgsm_binary_surrogate_single_targeted_{l}.npz'.format(\n",
    "            st=surrogate_type, tt=target_type, k=m_i, l=median_class\n",
    "        ),\n",
    "        adv_ex=adv_ex, noise=noise, step_count=step_count, scores=scores\n",
    "    )\n",
    "    print(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_targeted, targeted = zip(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_i, (adv_ex, noise, step_count, scores) in enumerate(non_targeted):\n",
    "    np.savez_compressed(\n",
    "        'experiments/simple_cnn_{}_fgsm_white_single_non_targeted.npz'.format(f_i),\n",
    "        adv_ex=adv_ex, noise=noise, step_count=step_count, scores=scores\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_i, fold_res in enumerate(targeted):\n",
    "    for l_i, (adv_ex, noise, step_count, scores) in enumerate(fold_res):\n",
    "        np.savez_compressed(\n",
    "            'experiments/simple_cnn_{}_fgsm_white_single_targeted_{}.npz'.format(f_i, l_i),\n",
    "            adv_ex=adv_ex, noise=noise, step_count=step_count, scores=scores\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = target_model(dataset.train.X)\n",
    "train_predict = train_scores.argmax(axis=-1)\n",
    "train_correct = train_predict == dataset.train.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores = target_model(dataset.val.X)\n",
    "val_predict = val_scores.argmax(axis=-1)\n",
    "val_correct = val_predict == dataset.val.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = target_model(dataset.test.X)\n",
    "test_predict = test_scores.argmax(axis=-1)\n",
    "test_correct = test_predict == dataset.test.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import gcd\n",
    "    \n",
    "def lcm(a, b):\n",
    "    return (a * b) // gcd(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "i = 9\n",
    "train_mask = np.logical_and(train_correct, train_predict == i)\n",
    "train_count = train_mask.sum()\n",
    "val_mask = np.logical_and(val_correct, val_predict == i)\n",
    "val_count = val_mask.sum()\n",
    "test_mask = np.logical_and(test_correct, test_predict == i)\n",
    "test_count = test_mask.sum()\n",
    "\n",
    "vis_lcm = lcm(lcm(train_count, val_count), test_count)\n",
    "train_space = vis_lcm // train_count\n",
    "val_space = vis_lcm // val_count\n",
    "test_space = vis_lcm // test_count\n",
    "\n",
    "plt.plot(np.arange(train_count) * train_space, np.sort(train_scores[train_mask].max(axis=-1)))\n",
    "plt.plot(np.arange(val_count) * val_space, np.sort(val_scores[val_mask].max(axis=-1)))\n",
    "plt.plot(np.arange(test_count) * test_space, np.sort(test_scores[test_mask].max(axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fgsm(target_model, dataset.test.X[0:1], 0, 0.50, is_targeted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model_dir = 'models/different_seeds/2018-05-29_190930.bs-0128.lr-0.0010.seed-42/'\n",
    "target_model = TfModel(target_model_dir + '30-best_loss')\n",
    "with open(target_model_dir + 'config.json', 'r') as config_f:\n",
    "    config = json.load(config_f)\n",
    "dataset = Dataset.from_nprecord(config['dataset_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for batch in dataset.batch_over_test(batch_size=1000):\n",
    "    results.append(fgsm(target_model, batch.X, batch.y, 0.99999999, is_targeted=False))\n",
    "    print('.', end='')\n",
    "    \n",
    "adv_ex, noise, step_count, scores = zip(*results)\n",
    "\n",
    "adv_ex = np.concatenate(adv_ex)\n",
    "noise = np.concatenate(noise)\n",
    "step_count = np.concatenate(step_count)\n",
    "scores = np.concatenate(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "sorting = np.argsort(transfer_scores)\n",
    "sorting = sorting[step_count[sorting] < 512]\n",
    "\n",
    "plt.plot(scores[sorting])\n",
    "# plt.plot(transfer_scores[np.argsort(scores)])\n",
    "plt.plot(transfer_scores[sorting])\n",
    "plt.plot(step_count[sorting] / 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TfModel('models/different_seeds/2018-05-29_190734.bs-0128.lr-0.0010.seed-21/30-best_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_scores = 1 - model(adv_ex)[np.arange(10000), dataset.test.y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = dataset.train[0].X\n",
    "target_label = 0\n",
    "\n",
    "adv_ex, noise = fgsm(model, image, target_label, steps=64)\n",
    "prediction = model(adv_ex)[0, target_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer attack ###\n",
    "- transfering adversarial images between models trained on the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = [\n",
    "    'models/different_seeds/2018-05-29_190734.bs-0128.lr-0.0010.seed-21/30-best_loss',\n",
    "    'models/different_seeds/2018-05-29_190930.bs-0128.lr-0.0010.seed-42/30-best_loss',\n",
    "    'models/different_seeds/2018-05-29_191127.bs-0128.lr-0.0010.seed-63/30-best_loss',\n",
    "    'models/different_seeds/2018-05-29_191322.bs-0128.lr-0.0010.seed-84/30-best_loss'\n",
    "]\n",
    "models = [TfModel(model_path, 1000) for model_path in model_paths]\n",
    "dataset = Dataset.from_nprecord('datasets/split_fashion_mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = [\n",
    "    'models/different_seeds/2018-05-29_190930.bs-0128.lr-0.0010.seed-42/30-best_loss',\n",
    "    'models/surrogate_model/2018-05-30_001645.bs-0128.lr-0.0010.seed-84/30-best_loss',\n",
    "    'models/surrogate_model/2018-05-30_001954.bs-0128.lr-0.0010.seed-84/30-best_loss'\n",
    "]\n",
    "models = [TfModel(model_path, 1000) for model_path in model_paths]\n",
    "dataset = Dataset.from_nprecord('datasets/fashion_mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = [\n",
    "    'models/different_seeds/2018-05-29_190930.bs-0128.lr-0.0010.seed-42/30-best_loss',\n",
    "    'models/binary_surrogate_model/2018-05-31_122738.bs-0128.lr-0.0010.seed-42/90-best_loss'\n",
    "]\n",
    "models = [TfModel(model_path, 1000) for model_path in model_paths]\n",
    "dataset = Dataset.from_nprecord('datasets/fashion_mnist.npz')\n",
    "dataset = Dataset.sub_dataset(dataset, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_examples = []\n",
    "for batch in dataset.batch_over_test(batch_size=1000):\n",
    "    adversarial_examples.append(np.stack(\n",
    "        [fgsm(model, batch.X, batch.y, 0.999, is_targeted=False)[0] for model in models],\n",
    "        axis=1\n",
    "    ))\n",
    "    print('.', end='')\n",
    "    \n",
    "adversarial_examples = np.concatenate(adversarial_examples)\n",
    "\n",
    "scores = 1 - np.stack([\n",
    "    np.stack([\n",
    "        model(adversarial_examples[:, adv_i])[np.arange(len(dataset.test)), dataset.test.y] for model in models\n",
    "    ], axis=1)\n",
    "    for adv_i in range(len(models))\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "fig, ax = plt.subplots(len(models), 1, figsize=(8, 4))\n",
    "fig.tight_layout()\n",
    "\n",
    "for adv_i in range(len(models)):\n",
    "    ax[adv_i].hlines(0.5, 0, len(dataset.test), colors='g')\n",
    "    \n",
    "    for model_i in range(len(models)):\n",
    "        ax[adv_i].plot(np.sort(scores[:, adv_i, model_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
