\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

The effort to automate various processes in our lives has always been one of the key concepts of scientific research. The automation of mechanical work has already been solved to great extent by advances in engineering. On the contrary, automated processing of information has been solved just partially. Well defined tasks i.e., tasks with fully defined behaviour, can be solved, and the challenge lies just in effectivity of the solution. On the other hand, models solving tasks based on raw real word data, human level input and output or some degree of fuzziness are yet to be found or, if they exist, suffer from several shortcomings. Those tasks form the field of artificial intelligence. Even though the artificial intelligence has undergone several crisis, not being able to deliver on its promises, it is experiencing boom once again thanks to advances in machine learning.

The ability to learn is believed to be the key of our success, the success of the mankind as a species, and accounts to what we call the intelligence. Following this belief, the machine learning mimics the process of learning by automating extraction of knowledge from experience, with the aim to abstract and grasp the semantics of the task. This is reached by construction of mathematical functions, which for given, numericaly represented, observations return valid, numericaly represented, conclusions. Those functions often take form of composite paramteric functions, and to solve the task satisfactorily, the best possible composition -- architecture, together with the best possible set of parameters is looked for. The deep learning is current state of the art method of machine learning.

The deep learning is based on use of deep neural networks. Neural network is a structure of interconnected artificial neurons, with artificial neuron being unit computing non-linear transformation of linear combination of its inputs, passing this value further to other connected units. With increasing size of those networks in terms of unit count, the convenient abstraction of layers -- mutually dependent groups of mutually independent units, emerged. Early neural network based solutions used very few of those layers, mainly due to the hardware limitations, but with the advances in technology, the deep learning i.e., usage of many-layered neural networks, was established. Appart from rising complexity of the models, new types of layers were invented, namely the convolutional layers extracting the local context from observations. Recurrent neural networks enabling processing of sequences of data were invented as well.

It was the convolutional neural networks i.e., the deep neural networks using convolutional layers, that lift off the new era of image processing, part of the field of computer vision. One of the key tasks solved by computer vision techniques is the task of image classification, which lies in assigning a category from the set of possible categories, to the image. The subjects of those task cover a wide range, from classifying real world entities on photographs to medical applications and deciding if the PET/CT scan reports cancerous formations. Use cases with high demands on reliability, like security enforcing systems, or aforementioned medical applications, need to be resilient to mistakenly corrupted data or even targeted attacks.

Deep learning image classification solutions reports vulnerability to adversarial examples i.e., artificially created inputs that become misinterpreted. It has been showed that carefully crafted perturbations added to images may successfully lead to model failure, while being unnoticable for the human observer, or a different model. The issue of vulnerability to adversarial attacks does not apply only to the task of image classification, but it also concerns speech recognition, particularly use of virutal personal asistants; or image segmentation and object detection on which autonomous driving depends. It is of great importance to study those vulnerabilities, attacks and corresponding defences to improve reliability of such solutions.

% In this writing, we set the goal to explore adversarial attacks in image classification in the black-box scenario. We want to assess the suitability of genetic algorithms for this purpose. In order to compare proposed strategy, we will analyse surrogate models in the context of generation of adversarial examples by training multiple deep neural networks, both target models and surrogate models, of varying architectures and meassure the success rate and performance of aforementioned approaches.

The goal of this work is to explore adversarial attacks in image classification by deep networks in the black-box scenario. We want to assess the suitability of genetic algorithms as a generative procedure for finding adversarial examples. In order to compare the proposed strategy, a careful analysis of utilization of surrogate models in the context of generation of adversarial examples needs to be performed. The aim is to train multiple deep neural networks, both as target and surrogate models, of varying architectures in several contexts, such as targeted and non-targeted attacks, or complete vs. one-vs-all (binary) classification. The performance of aforementioned approaches will be compared with state of the art white-box attacks represented by the fast gradient sign method.

The structure of the thesis is as follows. In chapter \ref{sec:preliminaries} the task of image classification is defined, along with overview of available datasets for research purposes (section \ref{sec:cv}). The underlying theory of deep learning for the purpose of image classification (section \ref{sec:deep_learning}), along with theoretical background of genetic algorithms (section \ref{sec:ga_theory}), is presented. Chapter \ref{sec:advex} spans the definition of adversarial attacks, their taxonomy (section \ref{sec:advex_taxonomy}) and known attack strategies (sections \ref{sec:advex_gbm} and \ref{sec:advex_gan}). In chapter \ref{sec:solution}, we propose our solution (section \ref{sec:pga}). In chapter \ref{sec:experiments}, we analyse known aproaches (sections \ref{sec:whitebox_fgsm} and \ref{sec:surrogate_fgsm}) and compare them to our solution (section \ref{sec:blackbox_ga}), carrying out a multitude of experiments.
