{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "from evgena.datasets import load_nprecord\n",
    "from evgena.models import TfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_run = np.load('playground/ga_runs/18-04-15-19-55-56.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuals = ga_run['individuals']\n",
    "objectives = ga_run['objectives']\n",
    "fitnesses = ga_run['fitnesses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "# fig.tight_layout()\n",
    "\n",
    "ax.set_xlim(0.0000000001, 1)\n",
    "ax.set_xlabel('Target class prediction probability')\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.set_ylabel('mean SSIM')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(axis='both')\n",
    "ax.vlines(0.5, -1, 1, colors='g')\n",
    "\n",
    "for epoch, curr_objectives in enumerate(objectives):\n",
    "    ax.lines = []\n",
    "    ax.plot(*curr_objectives.transpose(), 'r+')\n",
    "    \n",
    "    fig.canvas.set_window_title('Current generation: {}'.format(epoch))\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fig, ax = plt.subplots(8, 8, figsize=(10, 10))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(64):\n",
    "    if i > len(individuals):\n",
    "        break\n",
    "    \n",
    "    ax[i // 8, i % 8].axis('off')\n",
    "    ax[i // 8, i % 8].imshow(individuals[i], cmap='plasma', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAugmentation:\n",
    "    def __init__(self):\n",
    "        graph = tf.Graph()\n",
    "        self.session = tf.Session(graph=graph)\n",
    "        \n",
    "        with graph.as_default():\n",
    "            # input placeholders\n",
    "            self.augmentations = tf.placeholder(tf.float32, [None, None, None, 1], name='augmentations')\n",
    "            self.base_images = tf.placeholder(tf.float32, [None, None, None, 1], name='base_images')  # TODO link dimensions??\n",
    "            \n",
    "            # resize augmentations to match images\n",
    "            resized_augmentations = tf.image.resize_images(\n",
    "                self.augmentations, tf.shape(self.base_images)[1:3],\n",
    "                method=tf.image.ResizeMethod.BILINEAR, align_corners=True\n",
    "            )\n",
    "            \n",
    "            # add together with augmentations reshaped\n",
    "            self.augmented_images = tf.clip_by_value(\n",
    "                self.base_images + tf.expand_dims(resized_augmentations, 1), 0.0, 1.1\n",
    "            )\n",
    "\n",
    "    def __call__(self, augmentations, base_images):\n",
    "        if len(augmentations.shape[1:]) == 2:\n",
    "            augmentations = np.expand_dims(augmentations, -1)\n",
    "        \n",
    "        if len(base_images.shape[1:]) == 2:\n",
    "            base_images = np.expand_dims(base_images, -1)\n",
    "        \n",
    "        return self.session.run(\n",
    "            self.augmented_images,\n",
    "            feed_dict={self.augmentations: augmentations, self.base_images: base_images}\n",
    "        )\n",
    "    \n",
    "augment_images = ImageAugmentation()\n",
    "model = TfModel('models/fashion_mnist_cnn/model', 'end_points/images', 'end_points/scores', batch_size=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(model(test_data.reshape(-1, 28, 28, 1))[:, target_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(model(test_data.reshape(-1, 28, 28, 1))[:, target_class] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(generalization[leaderboard[0]] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "train, test, synset, metadata = load_nprecord('fashion_mnist.npz')\n",
    "\n",
    "source_class = 0\n",
    "target_class = 5\n",
    "\n",
    "prediction_bound = 0.5\n",
    "ssim_bound = 0.2\n",
    "\n",
    "filtered_indices, *_ = np.where(np.logical_and(objectives[-1, :, 0] > prediction_bound, objectives[-1, :, 1] > ssim_bound))\n",
    "filtered_individuals = individuals[filtered_indices]\n",
    "filtered_objectives = objectives[-1, filtered_indices]\n",
    "\n",
    "test_data = test.X[test.y == source_class]\n",
    "test_individuals = filtered_individuals\n",
    "\n",
    "augmented_images = augment_images(test_individuals, test_data)\n",
    "augmented_images_batch_shaped = augmented_images.reshape(-1, *augmented_images.shape[2:4], 1)\n",
    "\n",
    "generalization = model(augmented_images_batch_shaped)[:, target_class].reshape(augmented_images.shape[:2])\n",
    "\n",
    "print('Mean test prediction: {:4f}, target predicted {} out of {}.'.format(generalization.mean(), np.sum(generalization > 0.5), generalization.size))\n",
    "\n",
    "leaderboard = np.flip(np.argsort(filtered_objectives[:,1]), 0)\n",
    "\n",
    "compare_fig, compare_ax = plt.subplots(1, 3, figsize=(13, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_i = leaderboard[0]\n",
    "image_i = 0\n",
    "\n",
    "compare_ax[0].imshow(test_data[image_i], cmap='gray', vmin=0, vmax=1)\n",
    "compare_ax[1].imshow(filtered_individuals[individual_i], cmap='plasma', vmin=-1, vmax=1)\n",
    "compare_ax[2].imshow(augmented_images[individual_i, image_i][:,:,0], cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
