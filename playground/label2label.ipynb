{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genetals.core import *\n",
    "from genetals.callbacks import GAStatus, MultiObjectiveReport\n",
    "from genetals.operators import TwoPointXover, BiasedMutation, ShuffleOperator, NSGAOperator\n",
    "from genetals.initializers import RandomStdInit\n",
    "from evgena.datasets import Dataset, images_to_BHWC\n",
    "from evgena.models import Model, TfModel\n",
    "from evgena.metrics import SSIM, mse\n",
    "# from evgena.genetals import Im\n",
    "from evgena.utils.large_files import maybe_download\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why so slow?\n",
    "\n",
    "class BestImgReport(CallbackBase):\n",
    "    def __init__(self, ax: plt.Axes = None, best_picker = None):\n",
    "        super(BestImgReport, self).__init__()\n",
    "        \n",
    "        if ax is None:\n",
    "            self._fig, self._ax = plt.subplots(1, 1)\n",
    "        else:\n",
    "            self._fig, self._ax = ax.figure, ax\n",
    "        \n",
    "        self._best_picker = (lambda fitness: fitness.argmax()) if (best_picker is None) else best_picker\n",
    "        \n",
    "    def __call__(self, ga: GeneticAlgorithm) -> None:\n",
    "        offspring = ga.capture(-1)\n",
    "        best_i = self._best_picker(offspring.fitnesses)\n",
    "        \n",
    "        self._ax.imshow(offspring.individuals[best_i], cmap='plasma', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiSigmaRandomInit(InitializerBase):\n",
    "    def __init__(self, individual_shape, sigmas = (1,), mu: np.ndarray = 0):\n",
    "        super(MultiSigmaRandomInit, self).__init__()\n",
    "\n",
    "        self._individual_shape = individual_shape\n",
    "        self._sigmas = sigmas\n",
    "        self._mu = mu\n",
    "\n",
    "    def __call__(self, population_size: int, *args, **kwargs) -> np.ndarray:\n",
    "        sigmas = np.tile(self._sigmas, (population_size + (len(self._sigmas) - 1)) // len(self._sigmas))[:population_size]\n",
    "        result = (np.random.random((population_size,) + tuple(self._individual_shape)) * 2) - 1\n",
    "\n",
    "        return self._mu + result * sigmas[:population_size].reshape(population_size, *([1] * len(self._individual_shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiSigmaRandomNormalInit(InitializerBase):\n",
    "    def __init__(self, individual_shape, sigmas = (1,), mu: np.ndarray = 0):\n",
    "        super(MultiSigmaRandomNormalInit, self).__init__()\n",
    "\n",
    "        self._individual_shape = individual_shape\n",
    "        self._sigmas = sigmas\n",
    "        self._mu = mu\n",
    "\n",
    "    def __call__(self, population_size: int, *args, **kwargs) -> np.ndarray:\n",
    "        sigmas = np.tile(self._sigmas, (population_size + (len(self._sigmas) - 1)) // len(self._sigmas))[:population_size]\n",
    "        result = np.random.standard_normal((population_size,) + tuple(self._individual_shape))\n",
    "\n",
    "        return self._mu + result * sigmas[:population_size].reshape(population_size, *([1] * len(self._individual_shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrePopulationInit(InitializerBase):\n",
    "    def __init__(self, prepopulation):\n",
    "        super(PrePopulationInit, self).__init__()\n",
    "\n",
    "        self._prepopulation = prepopulation\n",
    "\n",
    "    def __call__(self, population_size: int, *args, **kwargs) -> np.ndarray:\n",
    "        assert population_size == len(self._prepopulation), 'Wrong pop size'  # TODO maybe tile or so\n",
    "        \n",
    "        return self._prepopulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAugmentation:\n",
    "    def __init__(self):\n",
    "        graph = tf.Graph()\n",
    "        self.session = tf.Session(graph=graph)\n",
    "        \n",
    "        with graph.as_default():\n",
    "            # input placeholders\n",
    "            self.augmentations = tf.placeholder(tf.float32, [None, None, None, 1], name='augmentations')\n",
    "            self.base_images = tf.placeholder(tf.float32, [None, None, None, 1], name='base_images')  # TODO link dimensions??\n",
    "            \n",
    "            # resize augmentations to match images\n",
    "            resized_augmentations = tf.image.resize_images(\n",
    "                self.augmentations, tf.shape(self.base_images)[1:3],\n",
    "                method=tf.image.ResizeMethod.BILINEAR, align_corners=True\n",
    "            )\n",
    "            \n",
    "            # add together with augmentations reshaped\n",
    "            self.augmented_images = tf.clip_by_value(\n",
    "                self.base_images + tf.expand_dims(resized_augmentations, 1), 0.0, 1.1\n",
    "            )\n",
    "\n",
    "    def __call__(self, augmentations, base_images):\n",
    "        augmentations = images_to_BHWC(augmentations)        \n",
    "        base_images = images_to_BHWC(base_images)\n",
    "        \n",
    "        return self.session.run(\n",
    "            self.augmented_images,\n",
    "            feed_dict={self.augmentations: augmentations, self.base_images: base_images}\n",
    "        )\n",
    "    \n",
    "augment_images = ImageAugmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Images2LabelObjectiveFnc(ObjectiveFncBase):\n",
    "    def __init__(\n",
    "        self, model: Model, similarity_measure: Callable[[np.ndarray, np.ndarray], np.ndarray],\n",
    "        target_label: int, source_images: np.ndarray, shuffle: bool = True,\n",
    "        sample_size: int = 64, sample_ttl: float = 0.9):\n",
    "        super(Images2LabelObjectiveFnc, self).__init__()\n",
    "        \n",
    "        self._metrics = similarity_measure\n",
    "        self._model = model\n",
    "        self._target_label = target_label\n",
    "        self._source_images = source_images\n",
    "        self._sample_size = sample_size\n",
    "        self._sample_ttl = sample_ttl\n",
    "        self._shuffle_source = shuffle\n",
    "        \n",
    "        if self._shuffle_source:\n",
    "            self._source_index = np.random.permutation(len(self._source_images))\n",
    "        else:\n",
    "            self._source_index = np.arange(len(self._source_images))\n",
    "        \n",
    "        self._samples = np.recarray((self._sample_size,), dtype=[('index', np.int32), ('ttl', np.float32)])\n",
    "        self._samples.index = np.arange(self._sample_size)\n",
    "        self._samples.ttl = 1\n",
    "        \n",
    "        self._source_i = self._sample_size\n",
    "      \n",
    "    def __call__(self, individuals: np.ndarray) -> np.ndarray:\n",
    "        # fetch samples\n",
    "        images = self._source_images[self._source_index[self._samples.index]]\n",
    "        \n",
    "        # resolve ttl of samples\n",
    "        self._samples.ttl *= self._sample_ttl\n",
    "        death_mask = self._samples.ttl < np.random.random(len(self._samples))\n",
    "        \n",
    "        u_source_i = self._source_i + np.sum(death_mask)\n",
    "        if  u_source_i > len(self._source_images):\n",
    "            u_source_i -= len(self._source_images)\n",
    "            babies = np.concatenate((np.arange(self._source_i, len(self._source_images)), np.arange(u_source_i)))\n",
    "            np.random.shuffle(self._source_index)\n",
    "        else:\n",
    "            babies = np.arange(self._source_i, u_source_i)\n",
    "        self._source_i = u_source_i\n",
    "        \n",
    "        self._samples.index[death_mask] = babies\n",
    "        self._samples.ttl[death_mask] = 1\n",
    "        \n",
    "        # augment images\n",
    "        augmented_images = augment_images(individuals, images)\n",
    "        augmented_images_batch_shaped = augmented_images.reshape(-1, *augmented_images.shape[2:])\n",
    "        \n",
    "        # for each individual sample its predictions, copmute ssim mean ssim\n",
    "        norms = self._metrics(augmented_images_batch_shaped, np.expand_dims(images, 0).repeat(len(individuals), axis=0).reshape(augmented_images_batch_shaped.shape))\n",
    "        norms = norms.reshape(augmented_images.shape[:2])\n",
    "        logits = model(augmented_images_batch_shaped)[:, self._target_label]\n",
    "        logits = logits.reshape(augmented_images.shape[:2])\n",
    "                       \n",
    "        avg_norms = np.average(norms, axis=-1)\n",
    "        avg_logits = np.average(logits, axis=-1)\n",
    "        \n",
    "        # create array by merging columns\n",
    "        return np.stack((avg_logits, avg_norms), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TfModel('models/fashion_mnist_cnn/model', 'end_points/images', 'end_points/scores', batch_size=8192)\n",
    "\n",
    "fashion_mnist = Dataset.from_nprecord(maybe_download('datasets/fashion_mnist.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_class = 0\n",
    "target_class = 5\n",
    "images = Dataset.sub_dataset(fashion_mnist, [source_class], do_stratified=False).train.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = OperatorGraph()\n",
    "\n",
    "select_op = ShuffleOperator(graph.init_op)\n",
    "xover_op = TwoPointXover(select_op, 0.6)\n",
    "mutation_op = BiasedMutation(xover_op, sigma=0.1, l_bound=-1, u_bound=1)\n",
    "moea_op = NSGAOperator(graph.init_op, mutation_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "# fig.tight_layout()\n",
    "\n",
    "ax.set_xlim(0.0000000001, 1)\n",
    "ax.set_xlabel('Target class prediction probability')\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.set_ylabel('mean SSIM')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(axis='both')\n",
    "ax.vlines(0.5, -1, 1, colors='g')\n",
    "\n",
    "callbacks = [MultiObjectiveReport(ax), GAStatus(fig)] # TODO BestImgReport(ax[1], best_picker=lambda fit: np.argmax(np.sum(fit, axis=-1)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- uniform vs std **norm** distributions??\n",
    "- persisting ga - pickle, joblib?\n",
    "- callback for intermediate individual checking\n",
    "- ssim border sensitivity??\n",
    "\n",
    "- ga to string method/repr\n",
    "\n",
    "- crossover based on adjacency on pareto-optimal front\n",
    "- new model (simillar to current/different)\n",
    "- ssim not same as skimage.measure.compare_ssim\n",
    "\n",
    "- compare with gradient based methods\n",
    "- joint approach? operator based on local search on loss functions\n",
    "- run GA and train classifier simultaneously, use gradients in GA operator\n",
    "- try to get class representant from scratch (model reverse engineering) - feature explanations, generating \"real-world\" examples\n",
    "- try to train inverse mapping?\n",
    "\n",
    "- z nuly tričko\n",
    "- uniformní crossover\n",
    "\n",
    "- specifikovat a určit co ano/co ne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GeneticAlgorithm(\n",
    "#     initializer=PrePopulationInit(first_run[0].individuals),\n",
    "    initializer=MultiSigmaRandomNormalInit((14, 14), (np.exp(np.linspace(3, 5, 100)) - 1) / (np.exp(5) - 1)),\n",
    "    operator_graph=graph,\n",
    "    objective_fnc=Images2LabelObjectiveFnc(model, lambda x, y: - mse(x, y), target_class, images, sample_size=64, sample_ttl = 0.98),\n",
    "    callbacks=callbacks,\n",
    "    results_dir='playground/ga_runs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time final_pop, fitnesses, objectives = ga.run(population_size=512, generation_cap=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time final_pop, fitnesses, objectives = ga.resume(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    ga = GeneticAlgorithm(\n",
    "    #     initializer=PrePopulationInit(first_run[0].individuals),\n",
    "        initializer=MultiSigmaRandomNormalInit((28, 28), (np.exp(np.linspace(0.5, 5, 100)) - 1) / (np.exp(5) - 1)),\n",
    "        operator_graph=graph,\n",
    "        objective_fnc=Images2LabelObjectiveFnc(model, target_class, images, sample_size=64, sample_ttl = 0.98),\n",
    "        callbacks=callbacks,\n",
    "        results_dir='playground/ga_runs'\n",
    "    )\n",
    "    \n",
    "    ga.run(population_size=512, generation_cap=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time result = ga.resume(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run = final_pop, fitnesses, objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_bound = 0.5\n",
    "ssim_bound = -1\n",
    "\n",
    "filtered_indices, *_ = np.where(np.logical_and(final_pop.objectives[:, 0] > prediction_bound, final_pop.objectives[:, 1] > ssim_bound))\n",
    "filtered_individuals = final_pop.individuals[filtered_indices]\n",
    "filtered_objectives = final_pop.objectives[filtered_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.X[test.y == source_class]\n",
    "test_individuals = filtered_individuals\n",
    "\n",
    "augmented_images = augment_images(test_individuals, test_data)\n",
    "augmented_images_batch_shaped = augmented_images.reshape(-1, *augmented_images.shape[2:4], 1)\n",
    "\n",
    "generalization = model(augmented_images_batch_shaped)[:, target_class].reshape(augmented_images.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generalization.mean(), np.sum(generalization > 0.5), generalization.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(filtered_objectives[:,1])\n",
    "# filtered_indices[np.argsort(filtered_objectives[:,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "individual_i = 6\n",
    "image_i = 8\n",
    "\n",
    "compare_fig, compare_ax = plt.subplots(1, 3, figsize=(13, 6))\n",
    "compare_ax[0].imshow(test_data[image_i], cmap='gray', vmin=0, vmax=1)\n",
    "compare_ax[1].imshow(filtered_individuals[individual_i], cmap='plasma', vmin=-1, vmax=1)\n",
    "compare_ax[2].imshow(augmented_images[individual_i, image_i][:,:,0], cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
